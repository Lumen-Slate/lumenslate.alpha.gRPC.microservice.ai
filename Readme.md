# ğŸ“˜ LumenSlate AI Microservice

An AI microservice designed for intelligent educational applications. It supports session-based interactions, assignment generation, and multiple AI-powered endpoints using gemini-2.5-flash-lite.

---

## ğŸš€ Features

- ğŸ§  Root Agent using `google.generativeai` for contextual AI conversations
- ğŸ—‚ï¸ Session storage via SQLite
- ğŸ“š Pre-seeded database with 150+ MCQs across English, Math, Science, History & Geography
- ğŸ› ï¸ Context generation, question segmentation, and variable detection via gemini-2.5-flash-lite
- ğŸ” Firebase Authentication middleware
- ğŸ“ Structured project layout for scalability
- ğŸ“œ Environment-based config for `dev`, `test`, `prod`
- ğŸ›°ï¸ **Supports gRPC endpoints only**

---

## ğŸ—‚ Project Structure

```

.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ root_agent/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ agent.py
â”‚   â”‚       â””â”€â”€ sub_agents/
â”‚   â”‚           â”œâ”€â”€ assessor/
â”‚   â”‚           â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚           â”‚   â””â”€â”€ agent.py
â”‚   â”‚           â”œâ”€â”€ assignment_generator_general/
â”‚   â”‚           â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚           â”‚   â””â”€â”€ agent.py
â”‚   â”‚           â”œâ”€â”€ assignment_generator_tailored/
â”‚   â”‚           â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚           â”‚   â””â”€â”€ agent.py
â”‚   â”‚           â””â”€â”€ report_card_generator/
â”‚   â”‚               â”œâ”€â”€ __init__.py
â”‚   â”‚               â””â”€â”€ agent.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ primary_agent_handler.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ README.txt
â”‚   â”œâ”€â”€ grpc_generated/
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â””â”€â”€ protos/
â”‚   â”‚           â”œâ”€â”€ ai_service_pb2_grpc.py
â”‚   â”‚           â””â”€â”€ ai_service_pb2.py
â”‚   â”œâ”€â”€ logic/
â”‚   â”‚   â”œâ”€â”€ agent_service.py
â”‚   â”‚   â”œâ”€â”€ context_generator.py
â”‚   â”‚   â”œâ”€â”€ mcq_variation_generator.py
â”‚   â”‚   â”œâ”€â”€ msq_variation_generator.py
â”‚   â”‚   â”œâ”€â”€ question_segmentation.py
â”‚   â”‚   â”œâ”€â”€ variable_detector.py
â”‚   â”‚   â””â”€â”€ variable_randomizer.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pydantic/
â”‚   â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”‚   â””â”€â”€ sqlite/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ models.py
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ context_generator_prompt.py
â”‚   â”‚   â”œâ”€â”€ mcq_variation_generator_prompt.py
â”‚   â”‚   â”œâ”€â”€ msq_variation_generator_prompt.py
â”‚   â”‚   â”œâ”€â”€ question_segmentation_prompt.py
â”‚   â”‚   â”œâ”€â”€ variable_detector_prompt.py
â”‚   â”‚   â””â”€â”€ variable_randomizer_prompt.py
â”‚   â”œâ”€â”€ protos/
â”‚   â”‚   â”œâ”€â”€ ai_service_pb2_grpc.py
â”‚   â”‚   â”œâ”€â”€ ai_service_pb2.py
â”‚   â”‚   â””â”€â”€ ai_service.proto
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ assessment_handler.py
â”‚   â”‚   â”œâ”€â”€ clean_text.py
â”‚   â”‚   â”œâ”€â”€ content_summarizer.py
â”‚   â”‚   â”œâ”€â”€ history_manager.py
â”‚   â”‚   â”œâ”€â”€ multimodal_handler.py
â”‚   â”‚   â”œâ”€â”€ populate_questions.py
â”‚   â”‚   â”œâ”€â”€ question_retriever.py
â”‚   â”‚   â”œâ”€â”€ report_card_tools.py
â”‚   â”‚   â””â”€â”€ subject_handler.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ grpc_service.py
â”‚   â””â”€â”€ grpc_server.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ logging_config.py
â”‚   â””â”€â”€ settings/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ dev.py
â”‚       â”œâ”€â”€ prod.py
â”‚       â””â”€â”€ test.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env.example
â”œâ”€â”€ Lumen_Slate.postman_collection.json
â”œâ”€â”€ service.yaml
â”œâ”€â”€ start.py
â””â”€â”€ README.md

```

---

## ğŸ§ª Setup Instructions

### 1. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # For Unix
venv\Scripts\activate      # For Windows
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Create Environment File

Copy the example file:

```bash
cp .env.example .env
```

Add your Gemini API key in `.env`:

```env
GOOGLE_API_KEY=your_api_key_here
```

---

## â–¶ï¸ Running the gRPC Server

```bash
python -m app.grpc_server
```

> gRPC endpoints are available as defined in `app/grpc_server.py`.

---

## ğŸ§  Populate the Question Database

```bash
python app/utils/populate_questions.py
```

> Seeds `my_agent_data.db` with 150+ MCQs (5 subjects, 3 difficulty levels).

---

## ğŸ›°ï¸ gRPC API Endpoints

The service exposes the following gRPC methods via the `AIService` service (see `app/protos/ai_service.proto`):

| Method                | Description                                      |
|-----------------------|--------------------------------------------------|
| GenerateContext       | Generates contextual passage                     |
| DetectVariables       | Identifies variables in a question               |
| SegmentQuestion       | Breaks a question into smaller parts             |
| GenerateMCQVariations | Creates MCQ variations                           |
| GenerateMSQVariations | Creates MSQ variations                           |
| FilterAndRandomize    | Extracts and randomizes variable filters         |
| Agent                 | Root AI agent for assignment/response generation |

> See the `.proto` file for message/request/response details.

---

## ğŸ“š API Documentation

* The gRPC service and message definitions are in [`app/protos/ai_service.proto`](app/protos/ai_service.proto).
* Use tools like [grpcurl](https://github.com/fullstorydev/grpcurl) or [Postman gRPC](https://blog.postman.com/postman-supports-grpc/) for testing.

---

## ğŸ“ Logging

Logs are stored in:

```txt
ai_microservice.log
```

---

## ğŸ“¦ Notes

* SQLite DB (`my_agent_data.db`) is ignored in Git
* DB can be regenerated anytime using the populate script
* Sessions and question data are stored in the same DB

---